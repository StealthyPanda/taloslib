{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Talos\n",
    "\n",
    "A library to deal with ML-pipelining in robotics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *All dependencies, including the package itself can be downloaded by running this at the root of this repo:*\n",
    "\n",
    "```bash\n",
    "pip install -e .\n",
    "```\n",
    "> *Make sure to activate your python environment, if you are using one.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main module can be imported as shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 main submodules:\n",
    "- `models` -> Contains Modules, Architectures related stuff.\n",
    "- `datapipe` -> Contains data pipelining (creating datasets, saving, loading them etc.) related stuff.\n",
    "- `training` -> Contains training models related stuff.\n",
    "- `utils` -> Contains general stuff, GPU stuff etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything in utils is directly accessible in the main `talos` module too, for ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mGPU(s) exist!\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talos.utils.gpu_exists() # or talos.gpu_exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 cuda devices...\n",
      "\u001b[33m0\u001b[0m\u001b[37m\t\u001b[0m\u001b[37mNVIDIA GeForce RTX 3060 Laptop GPU\u001b[0m\u001b[37m\t\u001b[0m\u001b[37m5937.94MB\u001b[0m\u001b[37m\t\u001b[0m\u001b[37m5.80GB\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "talos.utils.gpu_info() # or talos.gpu_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talos.datapipe as pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main class of interest here is `Dataset`. You can manage everything about datasets using this, from creating to saving to loading.\n",
    "\n",
    "Create a `Dataset` object first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names can be path-like. This can be used for better organisation of datasets in directories.\n",
    "data = pipe.Dataset(\n",
    "    name = 'testing/d1',\n",
    "    \n",
    "    # You can also add metadata for this dataset right here, using kw_args:\n",
    "    description = 'An example dataset',\n",
    "    forty_two = 'The meaning of life, the universe and everything.'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file:\u001b[90m{\n",
      "\u001b[0m\t\u001b[37m\u001b[92mrate\u001b[0m\u001b[0m : \u001b[33m32.0\u001b[0m,\n",
      "\t\u001b[37m\u001b[92mtype\u001b[0m\u001b[0m : \u001b[37mcolor/image_raw\u001b[0m,\n",
      "\t\u001b[37m\u001b[92mtopic\u001b[0m\u001b[0m : \u001b[37m/camera/color/image_raw\u001b[0m,\n",
      "\t\u001b[37m\u001b[92mnode\u001b[0m\u001b[0m : \u001b[37m/camera\u001b[0m,\n",
      "\t\u001b[37m\u001b[92mname\u001b[0m\u001b[0m : \u001b[37mdataset4\u001b[0m,\n",
      "\t\u001b[37m\u001b[92mpath\u001b[0m\u001b[0m : \u001b[37m/home/stealthypanda/collegestuff/robot_data/dataset4\u001b[0m,\n",
      "\t\u001b[37m\u001b[92mlinear_vel\u001b[0m\u001b[0m : \u001b[33m0.1\u001b[0m,\n",
      "\t\u001b[37m\u001b[92mangular_vel\u001b[0m\u001b[0m : \u001b[33m5\u001b[0m\n",
      "\u001b[90m}\n",
      "\u001b[0m\n",
      "Reading image 1076/1076...\n",
      "\u001b[32m\u001b[1mCreated dataset testing/d1!\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<talos.datapipe.Dataset at 0x7f097bf57e90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.create(\n",
    "    # path to the root directory of the dataset\n",
    "    path = '/home/stealthypanda/collegestuff/robot_data/datasets/dataset4',\n",
    "    \n",
    "    # Image size to resize all images to\n",
    "    image_size = (256, 256),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving datasets: (File is saved using `safetensors` library, and extension used is `.rdata`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dataset testing/d1 @ .talos/datasets/testing/d1.rdata\n",
      "Saved dataset testing/d1 @ example/dataset.rdata\n"
     ]
    }
   ],
   "source": [
    "# By default, datasets are saved @ .talos directory, using the dataset name as file name.\n",
    "data.save()\n",
    "\n",
    "#Or, you can provide a full path or filename to save it to a specific path\n",
    "data.save('example/dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading an existing `.rdata` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset testing/d1: \u001b[90m{\n",
      "\u001b[0m\t\u001b[37m\u001b[92mtype\u001b[0m\u001b[0m : \u001b[37mcolor/image_raw\u001b[0m,\n",
      "\t\u001b[37m\u001b[92mdescription\u001b[0m\u001b[0m : \u001b[37mAn example dataset\u001b[0m,\n",
      "\t\u001b[37m\u001b[92mangular_vel\u001b[0m\u001b[0m : \u001b[37m5\u001b[0m,\n",
      "\t\u001b[37m\u001b[92mrate\u001b[0m\u001b[0m : \u001b[37m32.0\u001b[0m,\n",
      "\t\u001b[37m\u001b[92msamples\u001b[0m\u001b[0m : \u001b[37m1076\u001b[0m,\n",
      "\t\u001b[37m\u001b[92mforty_two\u001b[0m\u001b[0m : \u001b[37mThe meaning of life, the universe and everything.\u001b[0m,\n",
      "\t\u001b[37m\u001b[92msize\u001b[0m\u001b[0m : \u001b[37m(256, 256)\u001b[0m,\n",
      "\t\u001b[37m\u001b[92mname\u001b[0m\u001b[0m : \u001b[37mtesting/d1\u001b[0m,\n",
      "\t\u001b[37m\u001b[92mlinear_vel\u001b[0m\u001b[0m : \u001b[37m0.1\u001b[0m\n",
      "\u001b[90m}\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "loaded = pipe.Dataset().load(name='testing/d1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start getting batches for training, first call `.split()` on the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data._split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you can keep calling `.get_batch()` to get new batches of (X, y):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 3, 32, 256, 256]), torch.Size([16, 7]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x, batch_y = data.get_batch(\n",
    "    batch_size = 16,\n",
    "    time_steps = 32,\n",
    "    include_only_last_y = True, # If true, for each datapoint in batch, only the last y for the last time step is taken.\n",
    "    split = 'train' # Can be 'train', 'test', 'valid'\n",
    ")\n",
    "batch_x.shape, batch_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module contains all model related stuff, making it easier for saving, loading and stuff. It also defines `TalosModule`, which is derived from the `torch.nn.Module`. It is the base class for all Modules defined in architectures as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import talos.models as tm\n",
    "from talos.utils import Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple example module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinear(tm.TalosModule):\n",
    "    \n",
    "    def __init__(self, inputs : int, outputs : int, name: str = None):\n",
    "        super().__init__(name)\n",
    "\n",
    "        self.layer = torch.nn.Linear(inputs, outputs)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.layer(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TalosModule` has a lot of useful features, such as `.disk_size()`, `.save()`, `.load()` etc. defined to make working with models a lot easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has  7.850K parameters, and uses  31.400KB on disk.\n"
     ]
    }
   ],
   "source": [
    "model = SimpleLinear(28 * 28, 10)\n",
    "print(\n",
    "f'The model has {model.nparams() / 1e3 : .3f}K parameters, \\\n",
    "and uses {model.disk_size() / 1e3 : .3f}KB on disk.'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving a model: (uses `safetensors`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model @ `test/m1.model`\n"
     ]
    }
   ],
   "source": [
    "model.save('test/m1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel = SimpleLinear(28 * 28, 10).load('test/m1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also common architectures defined as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "ffn = tm.FFN(\n",
    "    layers=[16, 16, 10],\n",
    "    activation=[F.relu, F.relu, lambda x:x]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module contains stuff related to training models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file:\u001b[90m{\n",
      "\u001b[0m\t\u001b[37m\u001b[92mrate\u001b[0m\u001b[0m : \u001b[33m32.0\u001b[0m,\n",
      "\t\u001b[37m\u001b[92mtype\u001b[0m\u001b[0m : \u001b[37mcolor/image_raw\u001b[0m,\n",
      "\t\u001b[37m\u001b[92mtopic\u001b[0m\u001b[0m : \u001b[37m/camera/color/image_raw\u001b[0m,\n",
      "\t\u001b[37m\u001b[92mnode\u001b[0m\u001b[0m : \u001b[37m/camera\u001b[0m,\n",
      "\t\u001b[37m\u001b[92mname\u001b[0m\u001b[0m : \u001b[37mdataset1\u001b[0m,\n",
      "\t\u001b[37m\u001b[92mpath\u001b[0m\u001b[0m : \u001b[37m/home/stealthypanda/collegestuff/robot_data/dataset1\u001b[0m,\n",
      "\t\u001b[37m\u001b[92mlinear_vel\u001b[0m\u001b[0m : \u001b[33m0.1\u001b[0m,\n",
      "\t\u001b[37m\u001b[92mangular_vel\u001b[0m\u001b[0m : \u001b[33m5\u001b[0m\n",
      "\u001b[90m}\n",
      "\u001b[0m\n",
      "Reading image 1152/1152...\n",
      "\u001b[32m\u001b[1mCreated dataset dataset_2!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "example_dataset = pipe.Dataset().create(\n",
    "    '/home/stealthypanda/collegestuff/robot_data/datasets/dataset1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dataset.y_vel = example_dataset.y_vel[::2]\n",
    "example_dataset.samples = len(example_dataset.y_vel)\n",
    "example_dataset.x_data = example_dataset.x_data[:example_dataset.samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_dataset._split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params: 1.234M \tModel size: 4.937MB\n"
     ]
    }
   ],
   "source": [
    "from talos.utils import Tensor\n",
    "\n",
    "\n",
    "class ExampleModel(tm.TalosModule):\n",
    "    \n",
    "    def __init__(self, name: str = None, *args, **kwargs) -> None:\n",
    "        super().__init__(name, *args, **kwargs)\n",
    "        \n",
    "        self.ublock = torch.nn.ModuleList([\n",
    "            tm.UNetBlock(c_in =  3, c_out = 16),\n",
    "            tm.UNetBlock(c_in = 16, c_out = 32),\n",
    "            tm.UNetBlock(c_in = 32, c_out = 64),\n",
    "            tm.UNetBlock(c_in = 64, c_out = 64),\n",
    "        ])\n",
    "        \n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        \n",
    "        self.ffn = tm.FFN([128, 32, 7], activation=[F.relu, F.relu, lambda x:x])\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        for block in self.ublock:\n",
    "            x = block(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.ffn(x)\n",
    "        return x\n",
    "\n",
    "example_model = ExampleModel()\n",
    "\n",
    "y = example_model(example_dataset.get_batch(1)[0])\n",
    "print(\n",
    "    f'Model params: {example_model.nparams()/1e6:.3f}M \\tModel size: {example_model.disk_size()/1e6:.3f}MB'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual training starts here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:\n",
      "\tStep 50/50 : 0.00456\n",
      "Epoch 2/5:\n",
      "\tStep 50/50 : 0.00017\n",
      "Epoch 3/5:\n",
      "\tStep 50/50 : 0.00179\n",
      "Epoch 4/5:\n",
      "\tStep 50/50 : 0.00032\n",
      "Epoch 5/5:\n",
      "\tStep 50/50 : 0.00470\n"
     ]
    }
   ],
   "source": [
    "timeline = talos.train(\n",
    "    example_model, example_dataset,\n",
    "    epochs = 5, steps = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it so far. More stuff to be added."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
